# Kurz AI pro veÅ™ejnou sprÃ¡vu - Kapitola 3: Parametry volÃ¡nÃ­ API

V tÃ©to kapitole se nauÄÃ­te, jak ovlivnit chovÃ¡nÃ­ a styl odpovÄ›dÃ­ modelu nastavenÃ­m vybranÃ½ch parametrÅ¯ pÅ™i volÃ¡nÃ­ API:

1. Volba modelu
2. Teplota (temperature)
3. UpovÃ­danost (verbosity)
4. Hloubka pÅ™emÃ½Å¡lenÃ­ (reasoning\_effort)

---

## 1. Volba modelu

PÅ™i nÃ¡vrhu aplikace vyuÅ¾Ã­vajÃ­cÃ­ velkÃ½ jazykovÃ½ model mÃ¡me na vÃ½bÄ›r mezi rÅ¯znÃ½mi modely. LiÅ¡Ã­ se:

- vÃ½robcem,
- zamÄ›Å™enÃ­m (text-to-text, text-to-image, speech-to-textâ€¦),
- vÃ½konem, rychlostÃ­ a cenou,
- schopnostmi (napÅ™. podpora tzv. reasoning â€“ â€pÅ™emÃ½Å¡lenÃ­â€œ).

V naÅ¡em kurzu se zamÄ›Å™Ã­me na **text-to-text** modely od OpenAI. PouÅ¾ijeme tÅ™i varianty modelu GPT-5:

- **gpt-5** â€“ nejvÃ½konnÄ›jÅ¡Ã­, ale takÃ© nejpomalejÅ¡Ã­ a nejdraÅ¾Å¡Ã­.
- **gpt-5-mini** â€“ kompromis mezi vÃ½konem a rychlostÃ­.
- **gpt-5-nano** â€“ nejrychlejÅ¡Ã­ a nejlevnÄ›jÅ¡Ã­, ale s omezenou kvalitou.

ğŸ“ **Ãškol:** SpusÅ¥te stejnÃ½ dotaz na vÅ¡echny tÅ™i varianty, zmÄ›Å™te dobu odezvy a porovnejte kvalitu odpovÄ›dÃ­.

```python
import time
from openai import OpenAI
from dotenv import load_dotenv
import os

# NaÄtenÃ­ API klÃ­Äe
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("API klÃ­Ä nenÃ­ nastaven v .env souboru.")

client = OpenAI(api_key=api_key)

prompt = [
        {
            "role": "developer",
            "content": "Jsi odbornÃ­k na pomoc uÅ¾ivateli pÅ™i Å™eÅ¡enÃ­ jeho Å¾ivotnÃ­ situace v obÄanskÃ©m Å¾ivotÄ›. VÅ¾dy poradÃ­Å¡, jak danou Å¾ivotnÃ­ situaci vyÅ™eÅ¡it z ÃºÅ™ednÃ­ho hlediska poskytnutÃ­m konkrÃ©tnÃ­ho ÃºÅ™ednÃ­ho postupu v podobÄ› ÄÃ­slovanÃ½ch krokÅ¯. Poskytuj krÃ¡tkÃ© a srozumitelnÃ© vysvÄ›tlenÃ­ kaÅ¾dÃ©ho kroku. PouÅ¾Ã­vej jednoduchou ÄeÅ¡tinu."
        },{
            "role": "developer",
            "content": "Nikdy nesmÃ­Å¡ v Å¾Ã¡dnÃ©m kroku postupu poskytovat radu v oboru, kterÃ©ho se dotaz uÅ¾ivatele tÃ½kÃ¡ (napÅ™. lÃ©kaÅ™skÃ© rady, stavebnÃ­ rady, atd.). Pouze mÅ¯Å¾eÅ¡ uÅ¾ivateli doporuÄit, aby odbornÃ­ka navÅ¡tÃ­vil. Toto doporuÄenÃ­ ale nesmÃ­Å¡ podmiÅˆovat Å¾Ã¡dnÃ½mi ÄasovÃ½mi, situaÄnÃ­mi Äi jinÃ½mi podmÃ­nkami."
        },{
            "role": "user",
            "content": (
                "BolÃ­ mÄ› hlava a mÃ¡m horeÄku. Co mÃ¡m dÄ›lat a mohu jÃ­t do prÃ¡ce?"
            )
        }
    ]

models = ["gpt-5", "gpt-5-mini", "gpt-5-nano"]

print("\n=== VÃ½sledky ===")
print(f"{'Model':<12} {'ÄŒas (s)':<10} OdpovÄ›Ä")
for model in models:
    start = time.time()
    response = client.responses.create(
        model=model,
        input=prompt)
    duration = time.time() - start
    print(f"{model:<12} {duration:<10.2f} {response.output_text.strip()}")
```


## 2. Teplota (temperature)

Teplota urÄuje mÃ­ru nÃ¡hodnosti pÅ™i generovÃ¡nÃ­ odpovÄ›di.

- **NÃ­zkÃ¡ hodnota (napÅ™. 0.2)** â†’ odpovÄ›di jsou konzistentnÄ›jÅ¡Ã­ a vÃ­ce deterministickÃ©.
- **VyÅ¡Å¡Ã­ hodnota (napÅ™. 0.8)** â†’ odpovÄ›di jsou rÅ¯znorodÄ›jÅ¡Ã­, ale mÅ¯Å¾e stoupat riziko â€halucinacÃ­â€œ.
- Rozsah hodnot: 0â€“2 (doporuÄeno 0â€“1).

ğŸ“ **Ãškol:** ZmÄ›Åˆte hodnotu `temperature` a pozorujte rozdÃ­ly ve vÃ½stupech.

```python
response = client.responses.create(
    model="gpt-5-mini",
    input=prompt,
    temperature=0.2
)

print("AI odpovÄ›Ä:")
print(response.output_text)
```

---

## 3. UpovÃ­danost (verbosity)

Parametr `verbosity` urÄuje mnoÅ¾stvÃ­ detailÅ¯ ve vÃ½stupu. Hodnoty:

- `low` â€“ struÄnÃ© odpovÄ›di.
- `medium` â€“ vyvÃ¡Å¾enÃ¡ mÃ­ra detailu.
- `high` â€“ velmi podrobnÃ© odpovÄ›di.

ğŸ“ **Ãškol:** VyzkouÅ¡ejte rÅ¯znÃ© ÃºrovnÄ› upovÃ­danosti pro model `gpt-5-mini`.

```python
for verbosity in ["low", "medium", "high"]:
    print(f"\n--- Verbosity: {verbosity} ---")
    response = client.responses.create(
        model="gpt-5-mini",
        input=prompt,
        text={
            "verbosity": verbosity
        }
    )
    print(response.output_text)
```

ğŸ“ **Ãškol:** PÅ™idejte do vÃ½stupu informaci o poÄtu vstupnÃ­ch a vÃ½stupnÃ­ch tokenÅ¯.

```python
for verbosity in ["low", "medium", "high"]:
    print(f"\n--- Verbosity: {verbosity} ---")
    start = time.time()
    response = client.responses.create(
        model="gpt-5-mini",
        input=prompt,
        text={
            "verbosity": verbosity
        }
    )
    duration = time.time() - start
    print(f"--- Duration: {duration:.2f} ---")
    print(f"--- Input tokens: {response.usage.input_tokens} ---")
    print(f"--- Output tokens: {response.usage.output_tokens} ---")
    print(f"--- Total tokens: {response.usage.total_tokens} ---")
    print(response.output_text)
```

---

## 4. Hloubka pÅ™emÃ½Å¡lenÃ­ (`reasoning_effort`)

Parametr `reasoning_effort` urÄuje, kolik internÃ­ho â€uvaÅ¾ovÃ¡nÃ­â€œ (reasoning tokenÅ¯) model vÄ›nuje pÅ™Ã­pravÄ› odpovÄ›di:

- `minimal` â€“ nejrychlejÅ¡Ã­ volba, model provÃ¡dÃ­ jen zÃ¡kladnÃ­ internÃ­ zpracovÃ¡nÃ­, vhodnÃ© pro jednoduchÃ© Ãºlohy (napÅ™. extrakce, formÃ¡tovÃ¡nÃ­), kde je klÃ­ÄovÃ¡ rychlost a nÃ­zkÃ¡ cena.
- `low` â€“ model vÄ›nuje mÃ­rnou mÃ­ru analÃ½zy; doporuÄeno pro bÄ›Å¾nÃ©, relativnÄ› jednoduchÃ© pÅ™Ã­pady.
- `medium` â€“ vÃ½chozÃ­ vyvÃ¡Å¾enÃ½ pÅ™Ã­stup; model vÄ›nuje pÅ™imÄ›Å™enÃ© ÃºsilÃ­ analÃ½ze i koherence.
- `high` â€“ nejhloubÄ›ji pÅ™emÃ½Å¡lejÃ­cÃ­ pÅ™Ã­stup; model investuje vÃ­ce prostÅ™edkÅ¯, vÃ½sledkem je typicky nejkvalitnÄ›jÅ¡Ã­ (a nejpomalejÅ¡Ã­) odpovÄ›Ä.

KaÅ¾dÃ¡ vyÅ¡Å¡Ã­ ÃºroveÅˆ mÅ¯Å¾e zlepÅ¡it kvalitu odpovÄ›dÃ­, ale takÃ© prodlouÅ¾it dobu generovÃ¡nÃ­ a zvÃ½Å¡it nÃ¡klady.

ğŸ“ **Ãškol:** Porovnejte odpovÄ›di pro rÅ¯znÃ© ÃºrovnÄ› `reasoning_effort` u modelu `gpt-5-mini`.

```python
for effort in ["minimal", "low", "medium", "high"]:
    print(f"\n--- Reasoning effort: {effort} ---")
    start = time.time()
    response = client.responses.create(
        model="gpt-5-mini",
        input=prompt,
        reasoning={
            "effort": effort
        }
    )
    duration = time.time() - start
    print(f"--- Duration: {duration:.2f} ---")
    print(f"--- Input tokens: {response.usage.input_tokens} ---")
    print(f"--- Output tokens: {response.usage.output_tokens} ---")
    print(f"--- Total tokens: {response.usage.total_tokens} ---")
    print(response.output_text)
```

---

## 5. DefaultnÃ­ nastavenÃ­

VraÅ¥me se jeÅ¡tÄ› k volÃ¡nÃ­ bez jakÃ½chkoliv parametrÅ¯ a prozkoumejme defaultnÃ­ nastavenÃ­.

ğŸ“ **Ãškol:** Prozkoumejte vÃ½sledek zpracovÃ¡nÃ­ modelem jeho detailnÃ­m prozkoumÃ¡nÃ­m a nejdÄ›te hodnoty defaultnÃ­ho nastavenÃ­.

```python
response = client.responses.create(
    model="gpt-5-mini",
    input=prompt
)

import json
parsed = json.loads(response.model_dump_json())
print(json.dumps(parsed, ensure_ascii=False, indent=2))
```

## 6. Kombinace parametrÅ¯

V reÃ¡lnÃ©m kÃ³du reÃ¡lnÃ© aplikace Äi sluÅ¾by typicky volÃ¡me model s konkrÃ©tnÃ­m nastavenÃ­m parametrÅ¯.
Ty mÅ¯Å¾eme kombinovat dle potÅ™eby.

ğŸ“ **Ãškol:** Zavolejte model s konkrÃ©tnÃ­m nastavenÃ­m parametrÅ¯ a prozkoumejte vÃ½sledek, abyste ovÄ›Å™ili, Å¾e model s nastavenÃ­m pracoval.

```python
response = client.responses.create(
    model="gpt-5-mini",
    input=prompt,
    text={
        "verbosity": "low"
    },
    reasoning={
        "effort": "minimal"
    }
)

import json
parsed = json.loads(response.model_dump_json())
print(json.dumps(parsed, ensure_ascii=False, indent=2))
```

---

## ShrnutÃ­

- **Volba modelu** ovlivÅˆuje kvalitu, rychlost i cenu.
- **Teplota** mÄ›nÃ­ mÃ­ru nÃ¡hodnosti vÃ½stupu.
- **UpovÃ­danost** Å™Ã­dÃ­ detailnost odpovÄ›dÃ­.
- **Hloubka pÅ™emÃ½Å¡lenÃ­** urÄuje, kolik internÃ­ analÃ½zy model provede a jakÃ© mnoÅ¾stvÃ­ reasoning tokenÅ¯ vyuÅ¾ije.

KombinacÃ­ tÄ›chto parametrÅ¯ mÅ¯Å¾ete doladit chovÃ¡nÃ­ modelu pro potÅ™eby vaÅ¡Ã­ aplikace.